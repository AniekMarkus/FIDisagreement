{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Modules / get functions in other Python scripts\n",
    "import app.results_explorer_utils as drc\n",
    "import app.results_explorer_figures as figs\n",
    "from app.results_explorer_helpers import *\n",
    "\n",
    "from app.results_explorer_input import output_folder, color_dict\n",
    "# TODO: set output_path in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Figures in notebook\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Manual run\n",
    "dataset=\"compas\"\n",
    "version=\"v0\"\n",
    "model=\"logistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance = pd.read_csv(output_folder / \"result\" / str(f\"{dataset}-{model}-aggregate_perf.csv\"), index_col=0, header=None)\n",
    "performance = performance.transpose() # performance = performance.transpose().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['perf_auc', 'perf_auprc', 'pred_non-zero']\n",
    "performance.loc[:,cols] = performance.loc[:,cols].apply(lambda c: c.astype(float), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "performance.groupby(by=['data', 'model', 'version'], group_keys=True, as_index=False).agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "cols = ['perf_auc', 'perf_auprc', 'pred_non-zero']\n",
    "\n",
    "for d in [\"compas\", \"german\", \"heartfailurestroke\", \"copdmortality\"]:\n",
    "    for m in [\"logistic\", \"nn\"]:\n",
    "        for v in [\"v0\"]:\n",
    "            performance = pd.read_csv(output_folder / \"result\" / str(f\"{d}-{m}-aggregate_perf.csv\"), index_col=0, header=None)\n",
    "            performance = performance.transpose().reset_index()\n",
    "\n",
    "            performance.loc[:,cols] = performance.loc[:,cols].apply(lambda c: c.astype(float), axis=1)\n",
    "\n",
    "            res = performance.groupby(by=['data', 'model', 'version'], group_keys=True, as_index=False).agg(['mean', 'std', 'count'])\n",
    "            res = res.perf_auc.reset_index()\n",
    "            res = res[(res.data == d) & (res.model == m) & (res.version == v)]\n",
    "            print(d + \" \" + m + \" \" + v + \" \" + str(np.round(res.loc[0,\"mean\"],3)) + \" \" + str(res.loc[0,\"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# German\n",
    "cols = ['perf_auc', 'perf_auprc', 'pred_non-zero']\n",
    "\n",
    "for d in [\"german\"]:\n",
    "    for m in [\"nn\"]:\n",
    "        # Get feature importance metrics for all versions\n",
    "        # version_list = os.listdir(output_folder / \"result\")\n",
    "        # version_list = list(filter(lambda v: re.findall(d, v), version_list))\n",
    "        # version_list = list(filter(lambda v: re.findall(m, v), version_list))\n",
    "        # version_list = list(set(map(lambda v: v.split(sep=\"-\")[1], version_list)))\n",
    "\n",
    "        version_list = ['v0', 'v24', 'v43', 'v42', 'v23', 'v33', 'v51', 'v12', 'v50', 'v39', 'v13', 'v41', 'v52', 'v16']\n",
    "        # version_list = ['v51', 'v12', 'v50', 'v39', 'v13', 'v41', 'v52', 'v16']\n",
    "        for v in version_list:\n",
    "                print(v)\n",
    "                performance = pd.read_csv(output_folder / \"result\" / str(f\"{d}-{m}-aggregate_perf.csv\"), index_col=0, header=None)\n",
    "                performance = performance.transpose().reset_index()\n",
    "\n",
    "                performance.loc[:,cols] = performance.loc[:,cols].apply(lambda c: c.astype(float), axis=1)\n",
    "\n",
    "                res = performance.groupby(by=['data', 'model', 'version'], group_keys=True, as_index=False).agg(['mean', 'std', 'count'])\n",
    "                res = res.perf_auc.reset_index()\n",
    "                print(res)\n",
    "                res = res[(res.data == d) & (res.model == m) & (res.version == v)]\n",
    "                print(d + \" \" + m + \" \" + v + \" \" + str(np.round(res.loc[0,\"mean\"],3)) + \" \" + str(res.loc[0,\"count\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}